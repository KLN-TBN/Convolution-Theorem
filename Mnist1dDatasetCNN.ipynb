{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KLN-TBN/Notebooks/blob/main/Mnist1dDatasetCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolution II -- MNIST1D\n",
        "\n",
        "This notebook investigates what happens when we use convolutional layers instead of fully-connected layers for the MNIST-1D from the coursework.\n",
        "\n",
        "We'll build the network from figure 10.7 in the notes.\n",
        "\n"
      ],
      "metadata": {
        "id": "t9vk9Elugvmi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import torch, torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "YrXWAH7sUWvU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this once to copy the train and validation data to your CoLab environment \n",
        "# or download from my github to your local machine if you are doing this locally\n",
        "if not os.path.exists('./train_data_x.npy'):\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/train_data_x.npy\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/train_data_y.npy\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/val_data_x.npy\n",
        "  !wget https://github.com/udlbook/udlbook/raw/main/practicals/val_data_y.npy  "
      ],
      "metadata": {
        "id": "wScBGXXFVadm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad40afc-a479-4783-93b0-cc1691983478"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-05 18:46:22--  https://github.com/udlbook/udlbook/raw/main/practicals/train_data_x.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/train_data_x.npy [following]\n",
            "--2023-01-05 18:46:23--  https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/train_data_x.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1280128 (1.2M) [application/octet-stream]\n",
            "Saving to: ‘train_data_x.npy’\n",
            "\n",
            "train_data_x.npy    100%[===================>]   1.22M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-01-05 18:46:24 (9.55 MB/s) - ‘train_data_x.npy’ saved [1280128/1280128]\n",
            "\n",
            "--2023-01-05 18:46:24--  https://github.com/udlbook/udlbook/raw/main/practicals/train_data_y.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/train_data_y.npy [following]\n",
            "--2023-01-05 18:46:25--  https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/train_data_y.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 32128 (31K) [application/octet-stream]\n",
            "Saving to: ‘train_data_y.npy’\n",
            "\n",
            "train_data_y.npy    100%[===================>]  31.38K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2023-01-05 18:46:25 (5.23 MB/s) - ‘train_data_y.npy’ saved [32128/32128]\n",
            "\n",
            "--2023-01-05 18:46:25--  https://github.com/udlbook/udlbook/raw/main/practicals/val_data_x.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/val_data_x.npy [following]\n",
            "--2023-01-05 18:46:26--  https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/val_data_x.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 640128 (625K) [application/octet-stream]\n",
            "Saving to: ‘val_data_x.npy’\n",
            "\n",
            "val_data_x.npy      100%[===================>] 625.12K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-01-05 18:46:26 (5.93 MB/s) - ‘val_data_x.npy’ saved [640128/640128]\n",
            "\n",
            "--2023-01-05 18:46:26--  https://github.com/udlbook/udlbook/raw/main/practicals/val_data_y.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/val_data_y.npy [following]\n",
            "--2023-01-05 18:46:27--  https://raw.githubusercontent.com/udlbook/udlbook/main/practicals/val_data_y.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16128 (16K) [application/octet-stream]\n",
            "Saving to: ‘val_data_y.npy’\n",
            "\n",
            "val_data_y.npy      100%[===================>]  15.75K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-01-05 18:46:27 (12.7 MB/s) - ‘val_data_y.npy’ saved [16128/16128]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "train_data_x = np.load('train_data_x.npy')\n",
        "train_data_y = np.load('train_data_y.npy')\n",
        "val_data_x = np.load('val_data_x.npy')\n",
        "val_data_y = np.load('val_data_y.npy')\n",
        "# Print out sizes\n",
        "print(\"Train data: %d examples (columns), each of which has %d dimensions (rows)\"%((train_data_x.shape[1],train_data_x.shape[0])))\n",
        "print(\"Validation data: %d examples (columns), each of which has %d dimensions (rows)\"%((val_data_x.shape[1],val_data_x.shape[0])))"
      ],
      "metadata": {
        "id": "8bKADvLHbiV5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "206bfbdd-f5ee-4627-c395-6d8884ee25d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data: 4000 examples (columns), each of which has 40 dimensions (rows)\n",
            "Validation data: 2000 examples (columns), each of which has 40 dimensions (rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network"
      ],
      "metadata": {
        "id": "_sFvRDGrl4qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# TODO Create a model with the folowing layers\n",
        "# 1. Convolutional layer, (input=length 40 and 1 channel, kernel size 3x3, stride 2, padding=\"valid\", 15 output channels ) \n",
        "# 2. ReLU\n",
        "# 3. Convolutional layer, (input=length 19 and 15 channels, kernel size 3x3, stride 2, padding=\"valid\", 15 output channels )\n",
        "# 4. ReLU\n",
        "# 5. Convolutional layer, (input=length 9 and 15 channels, kernel size 3x3, stride 2, padding=\"valid\", 15 output channels)\n",
        "# 6. ReLU\n",
        "# 7. Flatten (converts 4x15) to length 60\n",
        "# 8. Linear layer (input size = 60, output size = 10)\n",
        "# References:\n",
        "# https://pytorch.org/docs/1.13/generated/torch.nn.Conv1d.html?highlight=conv1d#torch.nn.Conv1d\n",
        "# https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html\n",
        "# https://pytorch.org/docs/1.13/generated/torch.nn.Linear.html?highlight=linear#torch.nn.Linear\n",
        "\n",
        "# Replace the following function which just runs a standard fully connected network\n",
        "# The flatten at the beginning is becuase we are passing in the data in a slightly different format.\n",
        "model = nn.Sequential(\n",
        "nn.Flatten(),\n",
        "nn.Linear(40, 100),\n",
        "nn.ReLU(),\n",
        "nn.Linear(100, 100),\n",
        "nn.ReLU(),\n",
        "nn.Linear(100, 10))\n",
        "\n",
        "model = nn.Sequential(\n",
        "nn.Conv1d(1, 15, 3, stride=2, padding=\"valid\"),\n",
        "nn.ReLU(),\n",
        "nn.Conv1d(15, 15, 3, stride=2, padding=\"valid\"),\n",
        "nn.ReLU(),\n",
        "nn.Conv1d(15, 15, 3, stride=2, padding=\"valid\"),\n",
        "nn.ReLU(),\n",
        "nn.Flatten(),\n",
        "nn.Linear(60,10))"
      ],
      "metadata": {
        "id": "FslroPJJffrh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# He initialization of weights\n",
        "def weights_init(layer_in):\n",
        "  if isinstance(layer_in, nn.Linear):\n",
        "    nn.init.kaiming_uniform_(layer_in.weight)\n",
        "    layer_in.bias.data.fill_(0.0)"
      ],
      "metadata": {
        "id": "YgLaex1pfhqz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You need all this stuff to ensure that PyTorch is deterministic\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "metadata": {
        "id": "zXRmxCQNnL_M"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed so always get same result (do not change)\n",
        "set_seed(1)\n",
        "\n",
        "# choose cross entropy loss function (equation 5.24 in the loss notes)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "# construct SGD optimizer and initialize learning rate and momentum\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
        "# object that decreases learning rate by half every 10 epochs\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "# create 100 dummy data points and store in data loader class\n",
        "x_train = torch.tensor(train_data_x.transpose().astype('float32'))\n",
        "y_train = torch.tensor(train_data_y.astype('long'))\n",
        "x_val= torch.tensor(val_data_x.transpose().astype('float32'))\n",
        "y_val = torch.tensor(val_data_y.astype('long'))\n",
        "\n",
        "# load the data into a class that creates the batches\n",
        "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
        "\n",
        "# Initialize model weights\n",
        "model.apply(weights_init)\n",
        "\n",
        "# loop over the dataset n_epoch times\n",
        "n_epoch = 50\n",
        "# store the loss and the % correct at each epoch\n",
        "losses_train = np.zeros((n_epoch))\n",
        "errors_train = np.zeros((n_epoch))\n",
        "losses_val = np.zeros((n_epoch))\n",
        "errors_val = np.zeros((n_epoch))\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  # loop over batches\n",
        "  for i, data in enumerate(data_loader):\n",
        "    # retrieve inputs and labels for this batch\n",
        "    x_batch, y_batch = data\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "    # forward pass -- calculate model output\n",
        "    pred = model(x_batch[:,None,:])\n",
        "    # compute the loss\n",
        "    loss = loss_function(pred, y_batch)\n",
        "    # backward pass\n",
        "    loss.backward()\n",
        "    # SGD update\n",
        "    optimizer.step()\n",
        "\n",
        "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
        "  pred_train = model(x_train[:,None,:])\n",
        "  pred_val = model(x_val[:,None,:])\n",
        "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
        "  _, predicted_val_class = torch.max(pred_val.data, 1)\n",
        "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
        "  errors_val[epoch]= 100 - 100 * (predicted_val_class == y_val).float().sum() / len(y_val)\n",
        "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
        "  losses_val[epoch]= loss_function(pred_val, y_val).item()\n",
        "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  val loss {losses_val[epoch]:.6f}, percent error {errors_val[epoch]:3.2f}')\n",
        "  \n",
        "  # tell scheduler to consider updating learning rate\n",
        "  scheduler.step()\n",
        "\n",
        "# Plot the results\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(errors_train,'r-',label='train')\n",
        "ax.plot(errors_val,'b-',label='validation')\n",
        "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
        "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
        "ax.set_title('Part I: Validation Result %3.2f'%(errors_val[-1]))\n",
        "ax.legend()\n",
        "ax.plot([0,n_epoch],[37.45, 37.45],'k:') # Original results. You should be better than this!\n",
        "plt.savefig('Coursework_I_Results.png',format='png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NYw8I_3mmX5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "00b2eb61-9010-4535-9ffe-f37e3243b81f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     0, train loss 0.296881, train error 10.55,  val loss 0.409004, percent error 14.65\n",
            "Epoch     1, train loss 0.202516, train error 6.90,  val loss 0.320119, percent error 11.05\n",
            "Epoch     2, train loss 0.176621, train error 6.35,  val loss 0.319308, percent error 11.80\n",
            "Epoch     3, train loss 0.161876, train error 6.20,  val loss 0.321456, percent error 10.90\n",
            "Epoch     4, train loss 0.189680, train error 6.75,  val loss 0.352156, percent error 12.25\n",
            "Epoch     5, train loss 0.132767, train error 4.30,  val loss 0.292157, percent error 9.40\n",
            "Epoch     6, train loss 0.100335, train error 3.10,  val loss 0.239983, percent error 8.35\n",
            "Epoch     7, train loss 0.096493, train error 3.57,  val loss 0.266108, percent error 8.80\n",
            "Epoch     8, train loss 0.103048, train error 3.68,  val loss 0.282785, percent error 9.60\n",
            "Epoch     9, train loss 0.083861, train error 2.78,  val loss 0.301583, percent error 9.80\n",
            "Epoch    10, train loss 0.059018, train error 1.88,  val loss 0.246866, percent error 7.70\n",
            "Epoch    11, train loss 0.047930, train error 1.30,  val loss 0.245477, percent error 8.05\n",
            "Epoch    12, train loss 0.049213, train error 1.35,  val loss 0.244559, percent error 7.50\n",
            "Epoch    13, train loss 0.045121, train error 1.18,  val loss 0.284187, percent error 8.65\n",
            "Epoch    14, train loss 0.036242, train error 0.78,  val loss 0.266375, percent error 8.25\n",
            "Epoch    15, train loss 0.042535, train error 1.28,  val loss 0.301743, percent error 9.05\n",
            "Epoch    16, train loss 0.035410, train error 0.95,  val loss 0.283789, percent error 8.20\n",
            "Epoch    17, train loss 0.028533, train error 0.57,  val loss 0.277962, percent error 8.05\n",
            "Epoch    18, train loss 0.028678, train error 0.62,  val loss 0.279000, percent error 8.50\n",
            "Epoch    19, train loss 0.027881, train error 0.62,  val loss 0.298484, percent error 8.40\n",
            "Epoch    20, train loss 0.022136, train error 0.38,  val loss 0.285985, percent error 8.20\n",
            "Epoch    21, train loss 0.020503, train error 0.28,  val loss 0.289705, percent error 8.35\n",
            "Epoch    22, train loss 0.019641, train error 0.25,  val loss 0.288676, percent error 8.05\n",
            "Epoch    23, train loss 0.020012, train error 0.32,  val loss 0.293256, percent error 7.95\n",
            "Epoch    24, train loss 0.020486, train error 0.32,  val loss 0.305957, percent error 8.55\n",
            "Epoch    25, train loss 0.017811, train error 0.22,  val loss 0.301657, percent error 8.35\n",
            "Epoch    26, train loss 0.017341, train error 0.15,  val loss 0.306151, percent error 8.25\n",
            "Epoch    27, train loss 0.017419, train error 0.20,  val loss 0.310148, percent error 8.55\n",
            "Epoch    28, train loss 0.016961, train error 0.25,  val loss 0.314317, percent error 8.50\n",
            "Epoch    29, train loss 0.017105, train error 0.25,  val loss 0.312315, percent error 8.20\n",
            "Epoch    30, train loss 0.015303, train error 0.18,  val loss 0.315394, percent error 8.45\n",
            "Epoch    31, train loss 0.015108, train error 0.15,  val loss 0.315654, percent error 8.40\n",
            "Epoch    32, train loss 0.014871, train error 0.12,  val loss 0.314865, percent error 8.55\n",
            "Epoch    33, train loss 0.014628, train error 0.15,  val loss 0.315902, percent error 8.40\n",
            "Epoch    34, train loss 0.014468, train error 0.12,  val loss 0.317483, percent error 8.35\n",
            "Epoch    35, train loss 0.014564, train error 0.12,  val loss 0.320722, percent error 8.50\n",
            "Epoch    36, train loss 0.014053, train error 0.15,  val loss 0.320588, percent error 8.45\n",
            "Epoch    37, train loss 0.014120, train error 0.10,  val loss 0.322812, percent error 8.40\n",
            "Epoch    38, train loss 0.013690, train error 0.10,  val loss 0.321700, percent error 8.50\n",
            "Epoch    39, train loss 0.015212, train error 0.15,  val loss 0.333215, percent error 8.45\n",
            "Epoch    40, train loss 0.013444, train error 0.10,  val loss 0.323251, percent error 8.40\n",
            "Epoch    41, train loss 0.013361, train error 0.10,  val loss 0.325637, percent error 8.45\n",
            "Epoch    42, train loss 0.013256, train error 0.10,  val loss 0.326754, percent error 8.60\n",
            "Epoch    43, train loss 0.013169, train error 0.07,  val loss 0.325075, percent error 8.55\n",
            "Epoch    44, train loss 0.013112, train error 0.07,  val loss 0.327795, percent error 8.65\n",
            "Epoch    45, train loss 0.013037, train error 0.07,  val loss 0.326300, percent error 8.75\n",
            "Epoch    46, train loss 0.012928, train error 0.07,  val loss 0.328607, percent error 8.60\n",
            "Epoch    47, train loss 0.012944, train error 0.07,  val loss 0.326701, percent error 8.55\n",
            "Epoch    48, train loss 0.012890, train error 0.10,  val loss 0.331457, percent error 8.55\n",
            "Epoch    49, train loss 0.012713, train error 0.07,  val loss 0.330145, percent error 8.60\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}